{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Student Information\n",
    "Name: 陳妘儒\n",
    "\n",
    "Student ID: 113065541\n",
    "\n",
    "GitHub ID: rheayunru\n",
    "\n",
    "Kaggle name: googoose\n",
    "\n",
    "Kaggle private scoreboard snapshot:![pic0.png](./img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Version Progression**\n",
    "\n",
    "#### **v1: Baseline Naive Bayes**\n",
    "\n",
    "**Reason for Starting Point:** Naive Bayes is a classic baseline model for text classification. Combined with TF-IDF, it enables the rapid establishment of a measurable starting point to evaluate the foundational performance of the model. This version was chosen to simplify the model construction process and expedite experimentation.  \n",
    "\n",
    "**Methodology:**  \n",
    "- Utilized TF-IDF for text vectorization, limiting features to 5,000.  \n",
    "- Employed Multinomial Naive Bayes, a suitable choice for text classification.  \n",
    "\n",
    "**Preprocessing:**  \n",
    "- Combined tweet data, sentiment labels, and data identifiers to construct training and testing datasets.  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.37032  \n",
    "- **Private Score:** 0.35144\n",
    "\n",
    "**Analysis:** The model exhibits clear deficiencies in capturing text semantics as it infers solely based on conditional probabilities of words, without considering contextual information. However, it is highly efficient and resource-light, making it suitable as a first attempt. \n",
    "\n",
    "---\n",
    "\n",
    "#### **v2: Random Forest**\n",
    "\n",
    "**Reasons for Selection:**  \n",
    "1. To experiment with a tree-based nonlinear classification approach and evaluate its potential to enhance performance.  \n",
    "2. To balance class imbalance, making the model more suitable for real-world data distributions.\n",
    "\n",
    "**Methodology:**  \n",
    "- Applied TF-IDF feature engineering with a Random Forest Classifier.  \n",
    "- Used `compute_class_weight` to balance class imbalance.  \n",
    "\n",
    "**Preprocessing:**  \n",
    "- Cleaned tweet text by standardizing to lowercase and removing special characters.  \n",
    "- Split data into training and validation sets using stratified sampling.  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.24155  \n",
    "- **Private Score:** 0.22482 \n",
    " \n",
    "**Analysis:** The performance of Random Forest was lower than that of Naive Bayes, indicating that the model still lacks semantic understanding for text data. Additionally, the TF-IDF features might be too sparse, further reducing classification effectiveness. \n",
    "\n",
    "---\n",
    "\n",
    "#### **v8: Twitter RoBERTa Base** \n",
    "\n",
    "**Motivation to Shift to Pretrained Models:** Transformer-based models (e.g., BERT and its variants) have outperformed traditional methods in natural language processing. Twitter RoBERTa is a pretrained model specifically fine-tuned for Twitter text, making it well-suited for social media data.  \n",
    "\n",
    "**Reasons for Selection:**  \n",
    "1. Pretrained models possess strong semantic understanding capabilities, compensating for the shortcomings of traditional methods.  \n",
    "2. Twitter RoBERTa's pretraining corpus aligns closely with the application scenario, maximizing performance potential.\n",
    "\n",
    "**Methodology:**  \n",
    "- Leveraged Hugging Face’s Twitter RoBERTa Base model.  \n",
    "- Preprocessing included removing social media-specific noise (e.g., @user mentions, URLs).  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.55604  \n",
    "- **Private Score:** 0.54167 \n",
    "\n",
    "**Analysis:** The model significantly improved classification performance, demonstrating its superior text understanding capabilities. However, its design is mainly tailored for binary classification or simpler sentiment analysis, with limited support for multi-class classification.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **v9: BERTweet** \n",
    "\n",
    "**Considerations for Further Optimization:** The results of Twitter RoBERTa highlighted the effectiveness of specialized models for social media text. However, its limitations in supporting multi-class classification led to the selection of BERTweet, a more Twitter-focused model, with additional fine-tuning.  \n",
    "\n",
    "**Reasons for Selection:**  \n",
    "1. BERTweet, optimized for Twitter text, might perform better in multi-class classification.  \n",
    "2. Custom loss functions and evaluation metrics (e.g., weighted F1 score) can more precisely reflect multi-class classification performance.\n",
    "\n",
    "**Methodology:**  \n",
    "- Used Hugging Face’s BERTweet Base model.  \n",
    "- Applied custom evaluation metrics (weighted accuracy and weighted F1 score).  \n",
    "- Fine-tuned hyperparameters, including a learning rate of 2e-5 and batch size of 16.  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.58559  \n",
    "- **Private Score:** 0.57223 \n",
    "\n",
    "**Analysis:** The model performance improved again, indicating that targeted fine-tuning strategies for multi-class problems are effective. However, the higher computational resource and training time costs must be considered.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **v11: Twitter RoBERTa Large** \n",
    "\n",
    "**Reasons for Selection:**  \n",
    "1. Larger models offer higher performance ceilings, especially for applications requiring precise sentiment nuances.  \n",
    "2. Further adjusted the output layer to support multi-class classification.\n",
    "\n",
    "**Methodology:**  \n",
    "- Adopted Hugging Face’s Twitter RoBERTa Large model.  \n",
    "- Adjusted the output layer for multi-class classification.  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.59478  \n",
    "- **Private Score:** 0.58245\n",
    "\n",
    "**Analysis:** This model achieved the best performance of the entire experiment but required significantly more resources. Its extended training and inference times make it unsuitable for resource-constrained scenarios.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **v11.2: Optimized Twitter RoBERTa Large** \n",
    "\n",
    "**Optimization Goals:** To balance performance and resource consumption. To address the high resource demands of v11, efficiency was improved through mixed-precision training and other techniques.  \n",
    "\n",
    "**Reasons for Selection:**  \n",
    "1. Increasing batch size and using mixed precision effectively reduces training time.  \n",
    "2. Adding an early stopping callback improves training stability and prevents overfitting.\n",
    "\n",
    "**Methodology:**  \n",
    "- Conducted secondary fine-tuning on the v11 model:  \n",
    "  1. Increased batch size to 32 for improved computational efficiency.  \n",
    "  2. Used mixed-precision training (fp16) to reduce resource usage.  \n",
    "  3. Added early stopping callbacks to avoid overfitting.  \n",
    "  4. Reserved 20% of training data as a validation set.  \n",
    "\n",
    "**Results and Evaluation:**  \n",
    "- **Public Score:** 0.58886  \n",
    "- **Private Score:** 0.57584  \n",
    "\n",
    "**Analysis:** The optimization strategies significantly enhanced computational efficiency and stability, though with a slight performance sacrifice (likely due to additional hyperparameter adjustments). Overall, this is a resource-friendly improvement.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Version Comparison Table**\n",
    "\n",
    "| **Version** | **Method/Model**                | **Public Score** | **Private Score** | **Advantages**                                  | **Disadvantages**                          |\n",
    "|-------------|----------------------------------|------------------|-------------------|------------------------------------------------|--------------------------------------------|\n",
    "| **v1**      | Naive Bayes + TF-IDF            | 0.37032          | 0.35144           | Simple and fast; low resource demands          | Lacks contextual semantic understanding     |\n",
    "| **v2**      | Random Forest + TF-IDF          | 0.24155          | 0.22482           | Balances class imbalance; interpretable model | Underperforms; limited semantic understanding |\n",
    "| **v8**      | Twitter RoBERTa Base            | 0.55604          | 0.54167           | Adapts well to social media text; large improvement | Limited support for multi-class classification |\n",
    "| **v9**      | BERTweet                        | 0.58559          | 0.57223           | Fine-tuned for multi-class classification      | Increased resource requirements             |\n",
    "| **v11**     | Twitter RoBERTa Large           | 0.59478          | 0.58245           | Best performance; captures subtle sentiment differences | High training time and resource demands    |\n",
    "| **v11.2**   | Optimized Twitter RoBERTa Large | 0.58886          | 0.57584           | Enhanced stability; improved computational efficiency | Slightly reduced performance               |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary and Insights**  \n",
    "The progression from Naive Bayes to Twitter RoBERTa Large highlights the ongoing effort to balance model performance and resource efficiency. Each step involved evaluating the current approach's strengths and weaknesses while aligning with application needs. Key takeaways include:\n",
    "\n",
    "- **Baseline Models (v1, v2):** Simple and quick to deploy, serving as foundational benchmarks, but limited in semantic understanding.  \n",
    "- **Pretrained Models (v8, v9):** Utilize Transformers to significantly enhance classification performance, particularly with task-specific fine-tuning.  \n",
    "- **Optimized Models (v11, v11.2):** Deliver peak performance while requiring strategic resource management for practical deployment.  \n",
    "\n",
    "Each iteration addressed specific requirements and application contexts, ensuring choices were rational and meaningful in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### **Directions for Improvement**  \n",
    "- Combine the best performance of v11 with the efficient training strategies of v11.2.  \n",
    "- Explore model ensembles that integrate the rapid inference of lightweight models with the accuracy of larger models.  \n",
    "- Optimize the inference pipeline to reduce inference time, aligning better with practical application requirements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v11\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# 讀取 JSON 格式的推文數據，轉換為 DataFrame 格式\n",
    "with open('data/tweets_DM.json', \"r\") as file:\n",
    "    tweets_data = [json.loads(line) for line in file]\n",
    "tweets_df = pd.DataFrame([tweet[\"_source\"][\"tweet\"] for tweet in tweets_data])\n",
    "\n",
    "# 讀取情感標籤和數據集劃分文件\n",
    "emotion_df = pd.read_csv(\"data/emotion.csv\")\n",
    "data_identification_df = pd.read_csv(\"data/data_identification.csv\")\n",
    "\n",
    "# 分離訓練集和測試集\n",
    "train_ids = data_identification_df[data_identification_df[\"identification\"] == \"train\"]\n",
    "test_ids = data_identification_df[data_identification_df[\"identification\"] == \"test\"]\n",
    "\n",
    "# 合併數據集，過濾空值\n",
    "train_df = train_ids.merge(tweets_df, on=\"tweet_id\").merge(emotion_df, on=\"tweet_id\", how=\"left\")\n",
    "test_df = test_ids.merge(tweets_df, on=\"tweet_id\", how=\"left\")\n",
    "train_df = train_df.dropna(subset=[\"emotion\"])\n",
    "\n",
    "# 定義情感標籤並將其轉為數字\n",
    "emotion_labels = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"trust\", \"joy\"]\n",
    "train_df[\"label\"] = train_df[\"emotion\"].apply(lambda x: emotion_labels.index(x))\n",
    "\n",
    "# 創建 Hugging Face Dataset，僅保留文本和標籤\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\"]])\n",
    "\n",
    "\n",
    "# 加載預訓練模型和分詞器\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-large-emotion-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(emotion_labels),\n",
    "    ignore_mismatched_sizes=True  # 忽略維度不匹配的情況\n",
    ")\n",
    "\n",
    "# 顯式設置問題類型為單標籤分類\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "print(f\"Number of labels: {model.config.num_labels}\")\n",
    "\n",
    "\n",
    "# 定義分詞函數，確保長度和填充\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# 應用分詞至數據集\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# 確保標籤為整數類型\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": int(x[\"label\"])})  \n",
    "\n",
    "# 設置數據格式供模型使用\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "test_dataset = test_dataset.remove_columns([\"text\"])  # 僅保留必要的欄位\n",
    "print(test_dataset.column_names)\n",
    "test_dataset.set_format(\"torch\")\n",
    "\n",
    "\n",
    "# 訓練參數設置\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",   # 輸出目錄\n",
    "    eval_strategy=\"no\",  # 不進行評估\n",
    "    learning_rate=2e-5,  # 設置學習率\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,  # 訓練週期數\n",
    "    weight_decay=0.01,  # 權重衰減\n",
    "    save_total_limit=1,  # 最多保存1個模型\n",
    "    logging_dir=\"./logs\",\n",
    "    metric_for_best_model=\"accuracy\",  # 評估的最佳指標\n",
    ")\n",
    "\n",
    "# 創建訓練器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# 預測測試集\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "# 保存測試結果至 CSV 文件\n",
    "test_df[\"predicted_emotion\"] = [emotion_labels[label] for label in predicted_labels]\n",
    "test_df[[\"tweet_id\", \"predicted_emotion\"]].to_csv(\"predicted_emotions_v11.csv\", index=False)\n",
    "print(\"v11儲存✧*｡٩(ˊᗜˋ*)و✧*｡\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
